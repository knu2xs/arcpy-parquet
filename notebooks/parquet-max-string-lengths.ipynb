{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7247d2cd-05b0-4c02-9eac-8b6d6c16338d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "from typing import Union\n",
    "\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.dataset as ds\n",
    "\n",
    "from pyarrow.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c05fb0b-5ce0-466c-975e-c42ea13c7643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('D:/projects/arcpy-parquet/data/raw/foursquare/geoparquet')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_prj = Path.cwd().parent\n",
    "dir_data = dir_prj / 'data'\n",
    "\n",
    "gpqt_pth = dir_prj / \"data/raw/foursquare/geoparquet\"\n",
    "\n",
    "gpqt_pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8ff68837-0941-46a4-9147-4c547a411d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get max length of a column from the metadata\n",
    "get_col_max_len = lambda col: len(col.statistics.max) if isinstance(col.statistics.max, str) else None\n",
    "\n",
    "# get maximum lengths for each row group in the table metadata\n",
    "get_row_group_max_lengths = lambda rg: [get_col_max_len(rg.column(idx)) for idx in range(rg.num_columns)]\n",
    "\n",
    "\n",
    "def get_string_columns(dataset: Union[Path, Dataset]) -> list[str]:\n",
    "    \"\"\"Get list of string column names for a Parquet dataset\"\"\"\n",
    "    # create arrow dataset object if a path\n",
    "    if isinstance(dataset, Path):\n",
    "        dataset = ds.dataset(dataset, format='parquet')\n",
    "        \n",
    "    if not isinstance(dataset, Dataset):\n",
    "        raise ValueError('dataset must be a PyArrow Dataset or path to a Parquet dataset')\n",
    "\n",
    "    # get the string columns\n",
    "    str_col_lst = [col.name for col in dataset.schema if \"string\" in str(col.type)]\n",
    "\n",
    "    return str_col_lst\n",
    "\n",
    "\n",
    "def get_file_max_len(pqt_file: Union[str, Path]) -> dict[str, int]:\n",
    "    \"\"\"Get a list of maximum string lengths for a file by reading the metadata statistics\"\"\"\n",
    "    # get the table metadata\n",
    "    meta = pq.read_metadata(pqt_file)\n",
    "    \n",
    "    # get a list of maximum lengths for every row group in the metadata\n",
    "    max_len_lst_lst = [get_row_group_max_lengths(meta.row_group(idx)) for idx in range(meta.num_row_groups)]\n",
    "    \n",
    "    # zip the values into sets for each row\n",
    "    max_len_zipped_lst = [set(val for val in vals if val is not None) for vals in zip(*max_len_lst_lst)]\n",
    "\n",
    "    # get the maximum lengths in a single list of values\n",
    "    max_len_lst = [max(val) if len(val) > 0 else None for val in max_len_zipped_lst]\n",
    "\n",
    "    # create a dictionary of maximum lengths\n",
    "    max_len_dict = {nm: max_len for nm, max_len in zip(meta.schema.names, max_len_lst)}\n",
    "\n",
    "    return max_len_dict\n",
    "    \n",
    "\n",
    "def get_parquet_max_string_lengths(parquet_dataset: Union[str, Path]) -> dict[str, int]:\n",
    "    \"\"\"\n",
    "    For a Parquet datset, get the maximum string lengths for all string columns.\n",
    "\n",
    "    Args:\n",
    "        parquet_dataset: Path to Parquet dataset.\n",
    "    \"\"\"\n",
    "    # create a parquet dataset to work with\n",
    "    dataset = ds.dataset(gpqt_pth, format='parquet')\n",
    "    \n",
    "    # get maximum lengths for each column from the metadata for each file in the dataset\n",
    "    max_len_lst_lst = [list(get_file_max_len(fl).values()) for fl in dataset.files]\n",
    "    \n",
    "    # zip the values into sets for each row\n",
    "    max_len_zipped_lst = [set(val for val in vals if val is not None) for vals in zip(*max_len_lst_lst)]\n",
    "    \n",
    "    # get the maximum lengths in a single list of values\n",
    "    max_len_lst = [max(val) if len(val) > 0 else None for val in max_len_zipped_lst]\n",
    "    \n",
    "    # create a dictionary of maximum lengths\n",
    "    max_len_dict = {nm: max_len for nm, max_len in zip(dataset.schema.names, max_len_lst)}\n",
    "    \n",
    "    return max_len_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "53133fc0-909a-4455-ba6e-cd8d97ef1439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 42,\n",
       " 'latitude': None,\n",
       " 'longitude': None,\n",
       " 'address': 94,\n",
       " 'locality': 25,\n",
       " 'region': 2,\n",
       " 'postcode': 10,\n",
       " 'admin_region': None,\n",
       " 'post_town': None,\n",
       " 'po_box': 11,\n",
       " 'country': 2,\n",
       " 'date_created': 10,\n",
       " 'date_refreshed': 10,\n",
       " 'date_closed': 10,\n",
       " 'tel': 14,\n",
       " 'website': 106,\n",
       " 'email': 30,\n",
       " 'facebook_id': None,\n",
       " 'instagram': 15,\n",
       " 'twitter': 13,\n",
       " 'fsq_category_ids': 12,\n",
       " 'fsq_category_labels': 72,\n",
       " 'placemaker_url': None,\n",
       " 'unresolved_flags': None,\n",
       " 'dt': None,\n",
       " 'geometry': 24}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_parquet_max_string_lengths(gpqt_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65f43b5-db2d-4d87-812e-16beb69f91b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
